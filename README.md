# ğŸ¨ Totem Inteligente de Reciclagem - AnÃ¡lise de Tampinhas PlÃ¡sticas

> SoluÃ§Ã£o de IA para classificaÃ§Ã£o de tampinhas plÃ¡sticas usando Vision Transformer (ViT) fine-tuned

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa um **totem inteligente de reciclagem** que classifica **tampinhas plÃ¡sticas por cor** usando deep learning. A soluÃ§Ã£o utiliza um Vision Transformer prÃ©-treinado no ImageNet, fine-tunado com um dataset robusto de 2.400 imagens de tampinhas em diferentes cores.

### ğŸ¯ Objetivo Principal
Classificar tampinhas plÃ¡sticas com base em sua cor, facilitando a separaÃ§Ã£o automÃ¡tica em processos de reciclagem.

### ğŸ¨ Classes Suportadas (12 cores)
```
0 â†’ Vermelho      1 â†’ Azul          2 â†’ Verde       3 â†’ Amarelo
4 â†’ Branco        5 â†’ Preto         6 â†’ Laranja     7 â†’ Rosa
8 â†’ Roxo          9 â†’ Marrom        10 â†’ Cinza      11 â†’ Transparente
```

---

## ğŸ“Š Dataset

**Origem**: Kaggle - `color-cap` dataset
- **Total**: 2.400 imagens
- **Treino**: 2.100 imagens
- **ValidaÃ§Ã£o**: 200 imagens
- **Teste**: 100 imagens
- **Formato**: YOLO (object detection)
- **Tamanho mÃ©dio**: 1920Ã—1080 px
- **LocalizaÃ§Ã£o**: `datasets/color-cap/`

### DistribuiÃ§Ã£o de Classes
Todas as 12 cores estÃ£o representadas no dataset com distribuiÃ§Ã£o balanceada.

---

## ğŸš€ Quickstart

### 1. InstalaÃ§Ã£o

```bash
# Clonar/navegar para o repositÃ³rio
cd totem-ia

# Criar ambiente virtual (se necessÃ¡rio)
python -m venv venv

# Ativar ambiente virtual
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 2. Explorar o Dataset

```bash
python explore_dataset.py
```

Isto irÃ¡:
- âœ“ Analisar estrutura do dataset
- âœ“ Validar integridade das imagens
- âœ“ Gerar mapeamento de classes
- âœ“ Exibir estatÃ­sticas

### 3. Fine-tuning do Modelo

```bash
python finetune_caps.py
```

**ConfiguraÃ§Ãµes padrÃ£o:**
- Modelo base: `google/vit-base-patch16-224`
- Ã‰pocas: 15
- Batch size: 32
- Learning rate: 1e-4
- Otimizador: AdamW + Linear Scheduler
- Salva em: `models/cap-finetuned/`

**Tempo estimado**: 30-60 minutos (GPU) ou 2-3 horas (CPU)

### 4. Usar o Classificador

```python
from backend.cap_classifier import CapClassifier

# Inicializar com modelo prÃ©-treinado
classifier = CapClassifier(model_path="models/cap-finetuned")

# Classificar uma imagem
result = classifier.classify_image("path/to/tampinha.jpg")
print(result)

# Classificar mÃºltiplas imagens
results = classifier.classify_batch([
    "path/to/cap1.jpg",
    "path/to/cap2.jpg"
])

# Avaliar dataset
stats = classifier.evaluate_dataset("datasets/color-cap/test/images")
```

---

## ğŸ“ Estrutura do Projeto

```
totem-ia/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ cap_classifier.py         âœ… Classificador de tampinhas
â”‚   â”œâ”€â”€ ai_models.py              ğŸ“Š Modelos de IA
â”‚   â”œâ”€â”€ database.py               ğŸ’¾ Gerenciamento de BD
â”‚   â”œâ”€â”€ gamification.py           ğŸ® Sistema de gamificaÃ§Ã£o
â”‚   â”œâ”€â”€ image_analyzer.py         ğŸ–¼ï¸  AnÃ¡lise de imagens
â”‚   â”œâ”€â”€ main.py                   ğŸ”Œ LÃ³gica principal
â”‚   â”œâ”€â”€ models.py                 ğŸ“‹ Modelos de dados
â”‚   â””â”€â”€ vit_classifier.py         ğŸ¤– Classificador ViT genÃ©rico
â”‚
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ color-cap/                ğŸ¨ Dataset do Kaggle
â”‚       â”œâ”€â”€ train/
â”‚       â”‚   â”œâ”€â”€ images/           (2100 imagens)
â”‚       â”‚   â””â”€â”€ labels/           (2100 labels YOLO)
â”‚       â”œâ”€â”€ valid/
â”‚       â”‚   â”œâ”€â”€ images/           (200 imagens)
â”‚       â”‚   â””â”€â”€ labels/           (200 labels)
â”‚       â””â”€â”€ test/
â”‚           â”œâ”€â”€ images/           (100 imagens)
â”‚           â””â”€â”€ labels/           (100 labels)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ cap-finetuned/            ğŸ¤– Modelo fine-tuned (apÃ³s treino)
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ model.safetensors
â”‚       â”œâ”€â”€ classes.json
â”‚       â””â”€â”€ training_history.json
â”‚
â”œâ”€â”€ esp32/                         ğŸ”§ CÃ³digo ESP32
â”œâ”€â”€ images/                        ğŸ“· Imagens do projeto
â”‚
â”œâ”€â”€ finetune_caps.py              ğŸ“š Script de fine-tuning
â”œâ”€â”€ explore_dataset.py             ğŸ” AnÃ¡lise do dataset
â”œâ”€â”€ run_totem.py                   ğŸš€ Iniciar aplicaÃ§Ã£o
â”œâ”€â”€ vit_api_server.py              ğŸŒ Servidor API
â”œâ”€â”€ requirements.txt               ğŸ“¦ DependÃªncias
â”œâ”€â”€ .env                          ğŸ” ConfiguraÃ§Ãµes locais
â””â”€â”€ README.md                      ğŸ“– Este arquivo

```

---

## ğŸ› ï¸ Ferramentas Utilizadas

### Deep Learning
- **Transformers**: `google/vit-base-patch16-224` (224Ã—224 px)
- **Framework**: PyTorch 2.0+
- **Fine-tuning**: Hugging Face Transformers

### Processamento
- **VisÃ£o Computacional**: OpenCV, PIL/Pillow
- **Processamento de Imagens**: CUDA (GPU) / CPU

### Banco de Dados
- **SQLite**: `recycling_totem.db`
- **ORM**: SQLAlchemy (se configurado)

### API & Servidor
- **FastAPI** ou **Flask** para exposiÃ§Ã£o de endpoints

---

## ğŸ“Š Desempenho Esperado

| MÃ©trica | Esperado |
|---------|----------|
| AcurÃ¡cia (validaÃ§Ã£o) | 85-95% |
| AcurÃ¡cia (teste) | 80-90% |
| ConfianÃ§a mÃ©dia | 70-85% |
| Tempo/imagem | 50-100ms (GPU) |

---

## ğŸ¯ Fluxo de Uso

```
Imagem Tampinha
       â†“
[CapClassifier]
       â†“
[ViT Fine-tuned]
       â†“
ClassificaÃ§Ã£o + ConfianÃ§a
       â†“
[Banco de Dados]
       â†“
[Totem - Feedback ao UsuÃ¡rio]
```

---

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### Alterar Tamanho de Batch

Editar `finetune_caps.py`:
```python
train_loader = DataLoader(train_dataset, batch_size=64, ...)  # Aumentar para GPU com mais RAM
```

### Ajustar Taxa de Aprendizado

```python
history = finetuner.train(
    learning_rate=2e-4,  # Aumentar para convergÃªncia mais rÃ¡pida
    num_epochs=20        # Mais Ã©pocas para melhor generalizaÃ§Ã£o
)
```

### Usar CPU ao invÃ©s de GPU

```python
classifier = CapClassifier(device='cpu')
```

---

## ğŸ› Troubleshooting

### "CUDA out of memory"
- Reduzir `batch_size` para 16 ou 8
- Usar `device='cpu'`
- Liberar cache: `torch.cuda.empty_cache()`

### "Dataset not found"
- Verificar se `datasets/color-cap/` existe
- Executar `explore_dataset.py` para validar

### "Modelo nÃ£o classifica corretamente"
- Treinar novamente com `finetune_caps.py`
- Aumentar nÃºmero de Ã©pocas (atÃ© 20-30)
- Reduzir `learning_rate` para 5e-5

---

## ğŸ“ˆ PrÃ³ximos Passos

- [ ] IntegraÃ§Ã£o com cÃ¢mera do totem
- [ ] API REST completa
- [ ] Dashboard de monitoramento
- [ ] AnÃ¡lise de confianÃ§a em tempo real
- [ ] GamificaÃ§Ã£o com feedback do usuÃ¡rio
- [ ] DetecÃ§Ã£o de tampinhas mÃºltiplas (YOLO v8)

---

## ğŸ“ ReferÃªncias

- [Vision Transformer (ViT) Paper](https://arxiv.org/abs/2010.11929)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)
- [Kaggle color-cap Dataset](https://www.kaggle.com/datasets/your-dataset-link)

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob licenÃ§a [MIT/GPL - especificar].

## ğŸ‘¥ Autores

- **Carol** - Desenvolvedor
- **FIAP** - Instituto de EducaÃ§Ã£o

---

## ğŸ“ Suporte

Para dÃºvidas ou issues, abrir uma issue no repositÃ³rio ou contatar os responsÃ¡veis.

---

**Ãšltima atualizaÃ§Ã£o**: Outubro 2025
**Status**: âœ… Em desenvolvimento
