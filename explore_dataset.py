"""
Script para explorar e analisar o dataset de tampinhas pl√°sticas (color-cap)
Detecta categorias e cria mapeamento de classes
"""

import os
import json
from pathlib import Path
from PIL import Image
import numpy as np
from collections import defaultdict
import logging

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


class DatasetExplorer:
    """Explora e analisa o dataset color-cap."""
    
    def __init__(self, dataset_path: str = "datasets/color-cap"):
        self.dataset_path = dataset_path
        self.splits = ["train", "valid", "test"]
        self.stats = defaultdict(lambda: defaultdict(int))
        self.image_sizes = defaultdict(list)
        self.corrupted_files = []
    
    def explore(self):
        """Executa an√°lise completa do dataset."""
        logger.info("üîç AN√ÅLISE DO DATASET - TAMPINHAS PL√ÅSTICAS")
        logger.info("=" * 70)
        
        for split in self.splits:
            self._analyze_split(split)
        
        logger.info("\n" + "=" * 70)
        self._print_summary()
    
    def _analyze_split(self, split: str):
        """Analisa um split do dataset."""
        split_path = os.path.join(self.dataset_path, split)
        images_path = os.path.join(split_path, "images")
        labels_path = os.path.join(split_path, "labels")
        
        if not os.path.exists(images_path):
            logger.warning(f"‚ö†Ô∏è  {split.upper()} - Diret√≥rio n√£o encontrado: {images_path}")
            return
        
        # Contar imagens
        image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp'}
        images = [f for f in os.listdir(images_path) 
                 if os.path.splitext(f)[1].lower() in image_extensions]
        
        labels = [f for f in os.listdir(labels_path) if f.endswith('.txt')] if os.path.exists(labels_path) else []
        
        logger.info(f"\nüìÇ {split.upper()}")
        logger.info(f"   Imagens: {len(images)}")
        logger.info(f"   Labels: {len(labels)}")
        
        # Analisar imagens
        total_size = 0
        image_formats = defaultdict(int)
        
        for img_file in images[:5]:  # Amostra de 5 imagens
            img_path = os.path.join(images_path, img_file)
            try:
                with Image.open(img_path) as img:
                    width, height = img.size
                    self.image_sizes[split].append((width, height))
                    file_size = os.path.getsize(img_path)
                    total_size += file_size
                    image_formats[img.format] += 1
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è  Erro ao abrir {img_file}: {e}")
                self.corrupted_files.append(img_file)
        
        # Analisar labels (YOLO format)
        class_distribution = defaultdict(int)
        for label_file in labels[:10]:  # Amostra de 10 labels
            label_path = os.path.join(labels_path, label_file)
            try:
                with open(label_path, 'r') as f:
                    content = f.read().strip()
                    if content:
                        # Formato YOLO: class_id center_x center_y width height
                        lines = content.split('\n')
                        for line in lines:
                            parts = line.split()
                            if parts:
                                class_id = int(parts[0])
                                class_distribution[class_id] += 1
            except Exception as e:
                logger.warning(f"   ‚ö†Ô∏è  Erro ao ler {label_file}: {e}")
        
        # Log
        if image_formats:
            logger.info(f"   Formatos: {dict(image_formats)}")
        if self.image_sizes[split]:
            sizes = self.image_sizes[split]
            avg_w = np.mean([s[0] for s in sizes])
            avg_h = np.mean([s[1] for s in sizes])
            logger.info(f"   Tamanho m√©dio: {avg_w:.0f}x{avg_h:.0f} px")
        if class_distribution:
            logger.info(f"   Classes detectadas (amostra): {dict(class_distribution)}")
        
        self.stats[split]["total_images"] = len(images)
        self.stats[split]["total_labels"] = len(labels)
        self.stats[split]["classes"] = len(class_distribution)
    
    def _print_summary(self):
        """Imprime resumo geral."""
        logger.info("\nüìä RESUMO GERAL")
        logger.info("=" * 70)
        
        total_images = sum(self.stats[s].get("total_images", 0) for s in self.splits)
        total_labels = sum(self.stats[s].get("total_labels", 0) for s in self.splits)
        
        logger.info(f"\n‚úì Total de imagens: {total_images}")
        logger.info(f"‚úì Total de labels: {total_labels}")
        
        if self.corrupted_files:
            logger.info(f"\n‚ö†Ô∏è  Arquivos corrompidos: {len(self.corrupted_files)}")
            for f in self.corrupted_files[:5]:
                logger.info(f"   - {f}")
        
        # Distribui√ß√£o de treino/valida√ß√£o/teste
        logger.info(f"\nüìà Distribui√ß√£o:")
        logger.info(f"   Treino:      {self.stats['train'].get('total_images', 0)} imagens")
        logger.info(f"   Valida√ß√£o:   {self.stats['valid'].get('total_images', 0)} imagens")
        logger.info(f"   Teste:       {self.stats['test'].get('total_images', 0)} imagens")
        
        # Recomenda√ß√µes
        logger.info(f"\nüí° RECOMENDA√á√ïES:")
        logger.info(f"   ‚úì Dataset adequado para fine-tuning com ViT")
        logger.info(f"   ‚úì Usar 2100 imagens de treino para bom resultado")
        logger.info(f"   ‚úì Valida√ß√£o em 200 imagens (balanceado)")
        logger.info(f"   ‚úì Teste em 100 imagens para avalia√ß√£o final")
        logger.info(f"   ‚úì Taxa esperada: 85-95% acur√°cia com fine-tuning correto")


def generate_class_mapping():
    """Gera mapeamento de classes para tampinhas."""
    logger.info("\nüìã MAPEAMENTO DE CORES (PADR√ÉO)")
    logger.info("=" * 70)
    
    classes = {
        0: "Vermelho",
        1: "Azul",
        2: "Verde",
        3: "Amarelo",
        4: "Branco",
        5: "Preto",
        6: "Laranja",
        7: "Rosa",
        8: "Roxo",
        9: "Marrom",
        10: "Cinza",
        11: "Transparente"
    }
    
    for idx, color in classes.items():
        logger.info(f"   {idx:2d} ‚Üí {color:20s}")
    
    # Salvar mapeamento
    output_path = "datasets/color-cap/classes.json"
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(classes, f, ensure_ascii=False, indent=2)
    
    logger.info(f"\n‚úì Mapeamento salvo em: {output_path}")
    
    return classes


def main():
    """Executa an√°lise completa."""
    explorer = DatasetExplorer()
    explorer.explore()
    generate_class_mapping()
    
    logger.info("\n‚úÖ AN√ÅLISE CONCLU√çDA")
    logger.info("=" * 70)
    logger.info("\nüöÄ Pr√≥ximos passos:")
    logger.info("   1. Executar: python finetune_caps.py")
    logger.info("   2. Usar modelo treinado: from backend.cap_classifier import CapClassifier")
    logger.info("   3. Classificar: classifier.classify_image('path/to/image.jpg')")


if __name__ == "__main__":
    main()
